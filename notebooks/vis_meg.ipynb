{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from time import time\n",
    "from tqdm import tqdm, trange\n",
    "from termcolor import cprint\n",
    "# import wandb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from omegaconf import DictConfig, open_dict\n",
    "import hydra\n",
    "from hydra.utils import get_original_cwd\n",
    "\n",
    "from constants import device\n",
    "from torch.utils.data import DataLoader, RandomSampler, BatchSampler\n",
    "\n",
    "from meg_decoding.models import get_model, Classifier\n",
    "from meg_decoding.utils.get_dataloaders import get_dataloaders, get_samplers\n",
    "from meg_decoding.utils.loss import *\n",
    "from meg_decoding.dataclass.god import GODDatasetBase, GODCollator\n",
    "from meg_decoding.utils.loggers import Pickleogger\n",
    "from meg_decoding.utils.vis_grad import get_grad\n",
    "from meg_decoding.matlab_utils.load_meg import get_meg_data, roi, time_window, get_baseline\n",
    "\n",
    "from hydra import initialize, compose\n",
    "    with initialize(version_base=None, config_path=\"../configs/\"):\n",
    "        args = compose(config_name='20230417_sbj01_seq2stat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATAROOT = args.data_root\n",
    "processed_meg_path_pattern = os.path.join(DATAROOT, '{sub}/mat/{name}')\n",
    "label_path_pattern = os.path.join(DATAROOT, '{sub}/labels/{name}')\n",
    "trigger_meg_path_pattern = os.path.join(DATAROOT, '{sub}/trigger/{name}')\n",
    "processed_rest_meg_path_pattern = os.path.join(DATAROOT, '{sub}/mat/{name}')\n",
    "\n",
    "meg_name, label_name, trigger_name, rest_name = args.subjects[sub][split]['mat'][0], args.subjects[sub][split]['labels'][0], args.subjects[sub][split]['trigger'][0], args.subjects[sub][split]['rest'][0]\n",
    "\n",
    "\n",
    "processed_meg_path = processed_meg_path_pattern.format(sub=sub, name=meg_name)\n",
    "label_path = label_path_pattern.format(sub=sub, name=label_name)\n",
    "trigger_path = trigger_meg_path_pattern.format(sub=sub, name=trigger_name)\n",
    "processed_rest_meg_path = processed_rest_meg_path_pattern.format(sub=sub, name=rest_name)\n",
    "\n",
    "MEG_Data, image_features, labels, triggers = get_meg_data(meg_filepath, label_filepath, trigger_filepath,\n",
    "                 rest_mean=None, rest_std=None, split='train')\n",
    "\n",
    "roi_ids = roi(args)\n",
    "data = MEG_Data[roi_ods,:]\n",
    "# create raw\n",
    "info = mne.create_info(\n",
    "    ch_names=len(roi_ids),\n",
    "    sfreq=1000,\n",
    "    ch_types='meg',\n",
    ")\n",
    "raw = mne.io.RawArray(data, info)\n",
    "\n",
    "mne.viz.plot_raw_psd(raw)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meg_raw = np.stack([df[key] for key in df.keys() if \"MEG\" in key])  # ( 224, ~396000 )\n",
    "# NOTE: (kind of) confirmed that last 16 channels are REF\n",
    "meg_raw = meg_raw[:num_channels]  # ( 208, ~396000 )\n",
    "\n",
    "meg_filtered = mne.filter.filter_data(\n",
    "    meg_raw, sfreq=brain_orig_rate, l_freq=brain_filter_low, h_freq=brain_filter_high,\n",
    ")\n",
    "\n",
    "# To 120 Hz\n",
    "meg_resampled = mne.filter.resample(\n",
    "    meg_filtered, down=brain_orig_rate / brain_resample_rate,\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from meg_decoding.utils.reproducibility import seed_worker\n",
    "# NOTE: We do need it (IMHO).\n",
    "if args.reproducible:\n",
    "    os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "    torch.use_deterministic_algorithms(True)\n",
    "    random.seed(0)\n",
    "    np.random.seed(0)\n",
    "    torch.manual_seed(0)\n",
    "    g = torch.Generator()\n",
    "    g.manual_seed(0)\n",
    "    seed_worker = seed_worker\n",
    "else:\n",
    "    g = None\n",
    "    seed_worker = None\n",
    "\n",
    "\n",
    "train_dataset = GODDatasetBase(args, 'train')\n",
    "val_dataset = GODDatasetBase(args, 'val')\n",
    "with open_dict(args):\n",
    "    args.num_subjects = train_dataset.num_subjects\n",
    "    print('num subject is {}'.format(args.num_subjects))\n",
    "\n",
    "\n",
    "if args.use_sampler:\n",
    "    test_size = val_dataset.Y.shape[0]\n",
    "    train_loader, test_loader = get_samplers(\n",
    "        train_dataset,\n",
    "        val_dataset,\n",
    "        args,\n",
    "        test_bsz=test_size,\n",
    "        collate_fn=GODCollator(args),)\n",
    "\n",
    "else:\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=args.batch_size,\n",
    "        drop_last=True,\n",
    "        shuffle=True,\n",
    "        num_workers=args.num_workers,\n",
    "        pin_memory=True,\n",
    "        worker_init_fn=seed_worker,\n",
    "        generator=g,\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=args.batch_size,\n",
    "        drop_last=True,\n",
    "        shuffle=False,\n",
    "        num_workers=args.num_workers,\n",
    "        pin_memory=True,\n",
    "        worker_init_fn=seed_worker,\n",
    "        generator=g,\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
