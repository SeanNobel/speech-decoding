defaults:
  - subjects: patternA


# ====== Path settings =======
data_root: '/work/project/MEG_GOD/GOD_dataset/'
save_root: '/home/yainoue/meg2image/results/20230426_all_seq2stat_cv_norm_wo_dilation'
montage_path: './data/GOD/montage.csv'
ch_region_path: './data/GOD/ch_region.json'
root_dir: # dummy
# ====== Spatial Region settings =======
region:
  - occipital/left
  - occipital/right
  - frontal/left
  - frontal/right
  - temporal/left
  - temporal/right
  - parietal/left
  - parietal/right
  - central/left
  - central/right  

# ====== Time Region settings ======
window:
  start: 0.25 # [s]
  end: 0.45 # [s]
baseline: rest

# == Data pre-processing parameters === #
preprocs:
  brain_resample_rate: 240 # 1000 # Hz
  baseline_len_sec: 0
  brain_filter: null #[1.0, 60] # null is allowed
  last4layers: False       # if True, the brain_encoder's emsize will be 1024, not 512
  # subject_wise: True       # whether to scale each subject's EEG dataset individually (only for Brennan2018)
  clamp: True
  clamp_lim: 20

# ===== Training settings ====
use_wandb: false
reproducible: true
dataset: GOD
use_sampler: true
z_scoring: true
rest_duration: 60
num_workers: 6
batch_size: 256 # original: 64, paper: 128
updates: 1200
lr: 3e-4
lr_scheduler: none # cosine or multistep or none
lr_multistep_mlstns: [0.4, 0.6, 0.8, 0.9]
lr_step_gamma: 0.5
epochs: 300
reduction: mean

# ==== Architecture ==== #
model: brain_endcoder_seq2static
ConvBlocks:
  ks: [5, 5, 3, 3, 3]
avgpools: 
  ks: [2,2,2,2]
D1: 128
D2: 256
F: 512 # NOTE: because if you set last4layers=False, then it's set to 1024 in the dataset class
K: 32
d_drop: 0.1 # for spatial attention, drop channels within d_drop of a randomly selected channel
seq2seq: false # これは、MEGが時系列をもち、ペアデータが静止画の時に必要な操作 or 時系列モデルなら他の方法も可能
init_temperature: 5.1
temp_trainable: true
criterion: crossentropy

normalize_image_features: True
memory_efficient: True
channel_size: null # dummy not use

