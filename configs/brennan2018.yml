# ==== Dataset ==== #
dataset: Brennan2018
seqLengthInSeconds: 3

# ==== Training ==== #
batch_size: 512
lr: 0.001
lr_gamma: 0.99
epochs: 200
last4layers: True # if True, the brain_encoder's emsize will be 1024, not 512
before: True # (if last4layers: either before drop, residuals, and layer_norm or after)

# ==== Architecture ==== #
D1: 270
D2: 320
F: 512 # NOTE: because if you set last4layers=False, then it's set to 1024 in the dataset class
K: 32

wav2vec_model: xlsr_53_56k

# == Hyperparameters that datasets should share === #
preprocs:
  audio_resample_rate: 16000 # before wav2vec
  lowpass_filter_width: 128

  brain_resample_rate: 120 # Hz
  brain_filter_low: 1.0 # Hz
  brain_filter_high: 60 # Hz

  seq_len: 3 # segment length in seconds

  shift_brain: True
  shift_len: 150 # ms

  last4layers: True
  before: True
